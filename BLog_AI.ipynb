{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Blog 3 AI"
      ],
      "metadata": {
        "id": "GQ3w9n5nw7ED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jUnFn8j5A7hP",
        "outputId": "b0ed16c7-2e1e-420e-e7ec-e786d36b1edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-7.4.4-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting langchain-core<1.0.0,>=0.3.37 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.37-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.19 (from langchain_community)\n",
            "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.12)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.8)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (3.4.1)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (0.28.1)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.26.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (0.14.0)\n",
            "Collecting brotli (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (4.2.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading duckduckgo_search-7.4.4-py3-none-any.whl (35 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.37-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: brotli, watchdog, socksio, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, langchain-core, duckduckgo-search, streamlit, langchain_huggingface, langchain, langchain_community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.35\n",
            "    Uninstalling langchain-core-0.3.35:\n",
            "      Successfully uninstalled langchain-core-0.3.35\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.18\n",
            "    Uninstalling langchain-0.3.18:\n",
            "      Successfully uninstalled langchain-0.3.18\n",
            "Successfully installed brotli-1.1.0 dataclasses-json-0.6.7 duckduckgo-search-7.4.4 httpx-sse-0.4.0 langchain-0.3.19 langchain-core-0.3.37 langchain_community-0.3.18 langchain_huggingface-0.1.2 marshmallow-3.26.1 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.7.1 pydeck-0.9.1 python-dotenv-1.0.1 socksio-1.0.0 streamlit-1.42.2 typing-inspect-0.9.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit transformers torch accelerate langchain_community langchain_huggingface duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "j4GWCGvwiDas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14edc65c-a7be-48bb-95eb-049c10edca35"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voyzomKauMUP",
        "outputId": "8a42afbc-2ed5-4cca-a786-a2df0bb18f63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ask3.py\n",
        "import streamlit as st\n",
        "from langchain_community.tools import TavilySearchResults  # Updated import\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "import re\n",
        "from typing import List, Dict\n",
        "import time\n",
        "from datetime import datetime\n",
        "import random\n",
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Blog-3 Generator\",\n",
        "    page_icon=\"✍️\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Enhanced CSS for styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    /* Main app styling */\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        color: #293241;\n",
        "        margin-bottom: 1rem;\n",
        "        font-weight: 800;\n",
        "        letter-spacing: -0.5px;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.8rem;\n",
        "        color: #293241;\n",
        "        margin: 1.8rem 0 1rem 0;\n",
        "        font-weight: 600;\n",
        "    }\n",
        "    .section-divider {\n",
        "        margin: 1.8rem 0;\n",
        "        border-top: 1px solid #e0e0e0;\n",
        "    }\n",
        "    .info-box {\n",
        "        background-color: #FE4B4A;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        color: white;\n",
        "    }\n",
        "    .error-box {\n",
        "        background-color: #FFEBEE;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 4px solid #E53935;\n",
        "    }\n",
        "    .success-box {\n",
        "        background-color: #e0f2f1;\n",
        "        color: #006064;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 4px solid #00897b;\n",
        "    }\n",
        "    /* Blog post formatting */\n",
        "    .blog-post {\n",
        "        font-family: 'Georgia', serif;\n",
        "        line-height: 1.7;\n",
        "        color: #333;\n",
        "        max-width: 100%;\n",
        "        margin: 0 auto;\n",
        "        padding: 20px;\n",
        "        background-color: #fff;\n",
        "        border-radius: 8px;\n",
        "        box-shadow: 0 2px 10px rgba(0,0,0,0.05);\n",
        "    }\n",
        "    .blog-post h1 {\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: 700;\n",
        "        color: #1a237e;\n",
        "        margin-bottom: 0.8rem;\n",
        "        line-height: 1.2;\n",
        "    }\n",
        "    .blog-post h2 {\n",
        "        font-size: 1.8rem;\n",
        "        font-weight: 600;\n",
        "        color: #283593;\n",
        "        margin: 1.8rem 0 1rem 0;\n",
        "        border-bottom: 2px solid #f5f5f5;\n",
        "        padding-bottom: 0.5rem;\n",
        "    }\n",
        "    .blog-post h3 {\n",
        "        font-size: 1.4rem;\n",
        "        font-weight: 600;\n",
        "        color: #303f9f;\n",
        "        margin: 1.5rem 0 0.8rem 0;\n",
        "    }\n",
        "    .blog-post p {\n",
        "        margin-bottom: 1.2rem;\n",
        "        font-size: 1.05rem;\n",
        "    }\n",
        "    .blog-post ul, .blog-post ol {\n",
        "        margin-bottom: 1.2rem;\n",
        "        padding-left: 1.5rem;\n",
        "    }\n",
        "    .blog-post li {\n",
        "        margin-bottom: 0.5rem;\n",
        "    }\n",
        "    .blog-post blockquote {\n",
        "        border-left: 4px solid #c5cae9;\n",
        "        padding-left: 1rem;\n",
        "        margin: 1.5rem 0;\n",
        "        color: #555;\n",
        "        font-style: italic;\n",
        "        background-color: #f3f5ff;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0 0.5rem 0.5rem 0;\n",
        "    }\n",
        "    .blog-post img {\n",
        "        max-width: 100%;\n",
        "        border-radius: 0.5rem;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .blog-post .callout {\n",
        "        background-color: #e8f5e9;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 4px solid #43a047;\n",
        "        margin: 1.5rem 0;\n",
        "    }\n",
        "    .blog-post .highlight {\n",
        "        background-color: #fffde7;\n",
        "        padding: 0.2rem 0.4rem;\n",
        "        border-radius: 3px;\n",
        "    }\n",
        "    .blog-post .cta-button {\n",
        "        display: inline-block;\n",
        "        background-color: #3f51b5;\n",
        "        color: white;\n",
        "        padding: 0.8rem 1.5rem;\n",
        "        border-radius: 4px;\n",
        "        text-decoration: none;\n",
        "        font-weight: 600;\n",
        "        margin: 1rem 0;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .blog-post .meta-info {\n",
        "        font-size: 0.9rem;\n",
        "        color: #757575;\n",
        "        margin-bottom: 2rem;\n",
        "        display: flex;\n",
        "        align-items: center;\n",
        "        gap: 1rem;\n",
        "    }\n",
        "    .blog-post .conclusion {\n",
        "        background-color: #f3f5ff;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-top: 2rem;\n",
        "    }\n",
        "    .blog-post code {\n",
        "        background-color: #f5f5f5;\n",
        "        padding: 0.2rem 0.4rem;\n",
        "        border-radius: 3px;\n",
        "        font-family: 'Courier New', monospace;\n",
        "        font-size: 0.9rem;\n",
        "    }\n",
        "    .tooltip-icon {\n",
        "        color: #9e9e9e;\n",
        "        font-size: 16px;\n",
        "        margin-left: 8px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Search Function using Tavily Search API with retry logic\n",
        "def search_web(query: str, num_results: int = 5) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Search the web using Tavily Search API and return relevant results.\n",
        "    Includes retry logic and improved error handling.\n",
        "    \"\"\"\n",
        "    max_retries = 3\n",
        "    retry_delay = 2\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Initialize the Tavily search tool with desired parameters\n",
        "            search = TavilySearchResults(\n",
        "                max_results=num_results,\n",
        "                search_depth=\"advanced\",  # \"basic\" or \"advanced\"\n",
        "                include_answer=True,\n",
        "                include_raw_content=True,\n",
        "                include_images=False  # Adjust if you need images\n",
        "            )\n",
        "            results = search.invoke(query)\n",
        "\n",
        "            # Process results to retrieve top num_results\n",
        "            processed_results = []\n",
        "            for result in results[:num_results]:\n",
        "                processed_results.append({\n",
        "                    'title': result.get(\"title\", \"No title\"),\n",
        "                    'link': result.get(\"url\", \"No link\"),\n",
        "                    'snippet': result.get(\"content\", \"No snippet\")\n",
        "                })\n",
        "            return processed_results\n",
        "\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                st.warning(f\"Search attempt {attempt+1} failed: {str(e)}. Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "                retry_delay *= 2  # Exponential backoff\n",
        "            else:\n",
        "                st.error(f\"Search failed after {max_retries} attempts: {str(e)}\")\n",
        "                return []\n",
        "    return []\n",
        "\n",
        "def process_search_results(results: List[Dict[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Process search results into a format useful for the LLM.\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        return \"\"\n",
        "    processed = \"Recent information from web search:\\n\\n\"\n",
        "    for i, result in enumerate(results, 1):\n",
        "        processed += f\"{i}. {result['title']}\\n\"\n",
        "        processed += f\"   URL: {result['link']}\\n\"\n",
        "        processed += f\"   Summary: {result['snippet']}\\n\\n\"\n",
        "    return processed\n",
        "\n",
        "def display_search_results(results: List[Dict[str, str]]):\n",
        "    \"\"\"\n",
        "    Display search results in the UI in a collapsible section.\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        st.warning(\"No search results found. The generated content will rely on the model's knowledge.\")\n",
        "        return\n",
        "    with st.expander(\"View Search Results\", expanded=False):\n",
        "        for i, result in enumerate(results, 1):\n",
        "            st.markdown(f\"**{i}. [{result['title']}]({result['link']})**\")\n",
        "            st.markdown(f\"*{result['snippet']}*\")\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_llm(temperature=0.7, max_tokens=1024):\n",
        "    \"\"\"\n",
        "    Load the HuggingFace LLaMA language model with configurable parameters.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        llm = HuggingFaceEndpoint(\n",
        "            repo_id='meta-llama/Meta-Llama-3-8B-Instruct',\n",
        "            huggingfacehub_api_token='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',  # Replace with your token if needed\n",
        "            task=\"text-generation\",\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=0.95,\n",
        "            repetition_penalty=1.1,\n",
        "            max_new_tokens=max_tokens\n",
        "        )\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load language model: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def trim_to_complete_sentence(text, target_word_count):\n",
        "    \"\"\"\n",
        "    Trims text to the last complete sentence that keeps the word count close to target.\n",
        "    \"\"\"\n",
        "    sentence_endings = r'[.!?][\\s\"\\')\\]}]*'\n",
        "    words = text.split()\n",
        "    current_word_count = len(words)\n",
        "    if current_word_count <= target_word_count:\n",
        "        return text\n",
        "    target_char_position = int(len(text) * (target_word_count / current_word_count))\n",
        "    sentence_end_matches = list(re.finditer(sentence_endings, text))\n",
        "    if not sentence_end_matches:\n",
        "        return ' '.join(words[:target_word_count])\n",
        "    last_valid_end = None\n",
        "    for match in sentence_end_matches:\n",
        "        if match.end() <= target_char_position:\n",
        "            last_valid_end = match\n",
        "        else:\n",
        "            if last_valid_end:\n",
        "                break\n",
        "            last_valid_end = match\n",
        "            break\n",
        "    if last_valid_end:\n",
        "        trimmed_text = text[:last_valid_end.end()].strip()\n",
        "        trimmed_words = len(trimmed_text.split())\n",
        "        if trimmed_words < target_word_count * 0.75:\n",
        "            next_match_index = sentence_end_matches.index(last_valid_end) + 1\n",
        "            if next_match_index < len(sentence_end_matches):\n",
        "                trimmed_text = text[:sentence_end_matches[next_match_index].end()].strip()\n",
        "        return trimmed_text\n",
        "    return text\n",
        "\n",
        "def format_blog_content(content, topic, tone):\n",
        "    \"\"\"\n",
        "    Apply enhanced markdown formatting to the generated blog content.\n",
        "    \"\"\"\n",
        "    current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
        "    word_count = len(content.split())\n",
        "    read_time = max(1, round(word_count / 200))\n",
        "    authors = [\"Aditya Sai\", \"Sai Laxman\", \"Bhakti Kushan\", \"Neeraj Kumar\", \"The Torchwood Team\"]\n",
        "    author = random.choice(authors)\n",
        "    has_headers = bool(re.search(r'^##?\\s+.+$', content, re.MULTILINE))\n",
        "    if not has_headers:\n",
        "        paragraphs = content.split('\\n\\n')\n",
        "        if len(paragraphs) >= 3:\n",
        "            intro = paragraphs[0]\n",
        "            body = '\\n\\n'.join(paragraphs[1:-1])\n",
        "            conclusion = paragraphs[-1]\n",
        "            body_parts = body.split('\\n\\n')\n",
        "            middle_idx = len(body_parts) // 2\n",
        "            if tone == \"Professional\":\n",
        "                section1_title = f\"Key Insights on {topic}\"\n",
        "                section2_title = f\"Professional Analysis\"\n",
        "            elif tone == \"Academic\":\n",
        "                section1_title = f\"Theoretical Framework\"\n",
        "                section2_title = f\"Analysis and Discussion\"\n",
        "            else:\n",
        "                section1_title = f\"Understanding {topic}\"\n",
        "                section2_title = f\"Practical Applications\"\n",
        "            section1 = '\\n\\n'.join(body_parts[:middle_idx])\n",
        "            section2 = '\\n\\n'.join(body_parts[middle_idx:])\n",
        "            content = f\"{intro}\\n\\n## {section1_title}\\n\\n{section1}\\n\\n## {section2_title}\\n\\n{section2}\\n\\n## Conclusion\\n\\n{conclusion}\"\n",
        "    if \">\" not in content and len(content) > 300:\n",
        "        paragraphs = content.split('\\n\\n')\n",
        "        for i, para in enumerate(paragraphs):\n",
        "            if 100 < len(para) < 300 and not para.startswith('#') and not para.startswith('>'):\n",
        "                paragraphs[i] = f\"> {para}\"\n",
        "                break\n",
        "        content = '\\n\\n'.join(paragraphs)\n",
        "    formatted_blog = f\"\"\"# {topic}\n",
        "\n",
        "<div class=\"meta-info\">\n",
        "<span>📅 {current_date}</span> <span>⏱️ {read_time} min read</span> <span>✍️ By {author}</span>\n",
        "</div>\n",
        "\n",
        "{content}\n",
        "\n",
        "<div class=\"conclusion\">\n",
        "<h3>About This Content</h3>\n",
        "<p>This article was generated using AI technology to provide insights on {topic}. While the content is AI-assisted, it's designed to be informative and valuable to readers interested in this topic.</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "    return formatted_blog\n",
        "\n",
        "def generate_blog_content(topic, word_count, audience, tone, format_options, llm, search_results=None):\n",
        "    \"\"\"\n",
        "    Generate blog content with improved prompt engineering and formatting options.\n",
        "    \"\"\"\n",
        "    search_context = \"\"\n",
        "    if search_results:\n",
        "        search_context = process_search_results(search_results)\n",
        "    format_text = \"\"\n",
        "    if \"headers\" in format_options:\n",
        "        format_text += \"- Include clear section headers to organize content\\n\"\n",
        "    if \"bullet_points\" in format_options:\n",
        "        format_text += \"- Use bullet points to highlight key information\\n\"\n",
        "    if \"quotes\" in format_options:\n",
        "        format_text += \"- Include relevant quotes or statistics to strengthen points\\n\"\n",
        "    if \"call_to_action\" in format_options:\n",
        "        format_text += \"- End with a strong call to action\\n\"\n",
        "    prompt = f\"\"\"<s>[INST] <<SYS>>\n",
        "You are a professional blog writer who creates well-structured, engaging content.\n",
        "You will write in clear, natural language without any technical codes or strange characters.\n",
        "Focus on delivering high-quality content following proper formatting guidelines.\n",
        "<</SYS>>\n",
        "\n",
        "Write a well-structured, engaging blog post about {topic} for {audience}.\n",
        "\n",
        "Content Requirements:\n",
        "- Approximately {word_count} words\n",
        "- Tone: {tone}\n",
        "- Target Audience: {audience}\n",
        "- Use proper markdown formatting for structure and emphasis\n",
        "\n",
        "Structure:\n",
        "1. Engaging introduction that hooks the reader\n",
        "2. Well-organized main body with logical flow\n",
        "3. Thoughtful conclusion\n",
        "\n",
        "{format_text}\n",
        "\n",
        "Formatting:\n",
        "- Use \"##\" for main sections, \"###\" for subsections\n",
        "- Use * or ** for emphasis\n",
        "- Format lists and quotes properly\n",
        "\n",
        "{search_context}\n",
        "\n",
        "IMPORTANT: Write ONLY in natural human language. Do NOT include code tokens, HTML, special characters, or placeholder text.\n",
        "[/INST]\n",
        "\"\"\"\n",
        "    prompt_template = PromptTemplate.from_template(prompt)\n",
        "    try:\n",
        "        response = llm.invoke(prompt_template.format())\n",
        "        generated_text = response if isinstance(response, str) else response.text\n",
        "        trimmed_content = trim_to_complete_sentence(generated_text, word_count)\n",
        "        formatted_content = format_blog_content(trimmed_content, topic, tone)\n",
        "        return formatted_content\n",
        "    except Exception as e:\n",
        "        st.error(f\"Content generation failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def display_formatted_blog(content):\n",
        "    \"\"\"\n",
        "    Display the blog with enhanced formatting and styling.\n",
        "    \"\"\"\n",
        "    st.markdown(f'<div class=\"blog-post\">{content}</div>', unsafe_allow_html=True)\n",
        "\n",
        "def main():\n",
        "    with st.sidebar:\n",
        "        try:\n",
        "            st.image(\"blogai.png\", width=150)\n",
        "        except:\n",
        "            st.title(\"BlogGen AI\")\n",
        "        st.markdown(\"## Configuration\")\n",
        "        with st.expander(\"Advanced Settings\", expanded=False):\n",
        "            temperature = st.slider(\"Creativity (Temperature)\", 0.1, 1.0, 0.7, 0.1,\n",
        "                                   help=\"Higher values make output more creative but less focused\")\n",
        "            max_tokens = st.slider(\"Max Output Length\", 500, 2048, 1024, 50,\n",
        "                                  help=\"Maximum number of tokens in the generated response\")\n",
        "        with st.expander(\"Blog Theme\", expanded=True):\n",
        "            theme = st.selectbox(\n",
        "                \"Choose a visual theme\",\n",
        "                [\"Standard\", \"Professional\", \"Academic\", \"Minimal\", \"Modern\"],\n",
        "                help=\"Changes the visual style of the generated blog\"\n",
        "            )\n",
        "            st.markdown(\"##### Current Theme: \" + theme)\n",
        "            st.markdown(\"<small>Theme affects visual styling only</small>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"<h1 class='main-header'>BlogGen AI </h1>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"<h3 class='sub-header'>Generate a new blog...</h3>\",unsafe_allow_html=True)\n",
        "    st.markdown(\"<p class='info-box'>Powered by LLaMA 2.</p>\", unsafe_allow_html=True)\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        topic = st.text_input(\"Blog Topic\",\n",
        "                             placeholder=\"e.g., Sustainable Fashion Trends 2025\",\n",
        "                             help=\"Be specific for better results\")\n",
        "        word_count = st.slider(\"Approximate Word Count\",\n",
        "                              min_value=200, max_value=2000, value=600, step=50,\n",
        "                              help=\"Longer content may take more time to generate\")\n",
        "    with col2:\n",
        "        audience = st.selectbox(\"Target Audience\",\n",
        "                               [\"General Public\", \"Business Professionals\", \"Researchers\",\n",
        "                                \"Content Creators\", \"Students\", \"Industry Experts\"],\n",
        "                               help=\"Tailors content to audience expectations\")\n",
        "        tone = st.selectbox(\"Content Tone\",\n",
        "                           [\"Professional\", \"Conversational\", \"Academic\", \"Enthusiastic\",\n",
        "                            \"Informative\", \"Persuasive\"],\n",
        "                           help=\"Sets the writing style and voice\")\n",
        "    st.markdown(\"<div class='section-divider'></div>\", unsafe_allow_html=True)\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "    with col1:\n",
        "        st.markdown(\"### Web Research\")\n",
        "        search_option = st.radio(\n",
        "            \"Web search for recent information?\",\n",
        "            [\"No Search\", \"Basic Search\", \"Comprehensive Search\"]\n",
        "        )\n",
        "    with col2:\n",
        "        generate_button = st.button(\"Generate Blog Content\", type=\"primary\", use_container_width=True)\n",
        "    if generate_button and topic:\n",
        "        try:\n",
        "            with st.spinner(\"Setting up the language model...\"):\n",
        "                llm = load_llm(temperature=temperature, max_tokens=max_tokens)\n",
        "                if llm is None:\n",
        "                    st.error(\"Failed to initialize the language model. Please try again.\")\n",
        "                    return\n",
        "            search_results = None\n",
        "            if search_option != \"No Search\":\n",
        "                num_results = 3 if search_option == \"Basic Search\" else 7\n",
        "                with st.spinner(f\"Searching for recent information about '{topic}'...\"):\n",
        "                    search_results = search_web(topic, num_results=num_results)\n",
        "                    if search_results:\n",
        "                        st.markdown(\"<p class='success-box'>✅ Found relevant information from web search</p>\", unsafe_allow_html=True)\n",
        "                        display_search_results(search_results)\n",
        "            with st.spinner(\"Generating blog content...\"):\n",
        "                blog_content = generate_blog_content(\n",
        "                    topic, word_count, audience, tone, [], llm, search_results\n",
        "                )\n",
        "            if blog_content:\n",
        "                st.markdown(\"<h2 class='sub-header'>Generated Blog Post</h2>\", unsafe_allow_html=True)\n",
        "                display_formatted_blog(blog_content)\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.download_button(\n",
        "                        label=\"Download as Markdown\",\n",
        "                        data=blog_content,\n",
        "                        file_name=f\"{topic.replace(' ', '_')}_blog.md\",\n",
        "                        mime=\"text/markdown\",\n",
        "                    )\n",
        "                with col2:\n",
        "                    plain_text = re.sub(r'[#*>_`]', '', blog_content)\n",
        "                    plain_text = re.sub(r'\\n{3,}', '\\n\\n', plain_text)\n",
        "                    st.download_button(\n",
        "                        label=\"Download as Plain Text\",\n",
        "                        data=plain_text,\n",
        "                        file_name=f\"{topic.replace(' ', '_')}_blog.txt\",\n",
        "                        mime=\"text/plain\",\n",
        "                    )\n",
        "                st.markdown(\"<div class='section-divider'></div>\", unsafe_allow_html=True)\n",
        "                st.markdown(\"### Your Feedback\")\n",
        "                feedback_col1, feedback_col2 = st.columns(2)\n",
        "                with feedback_col1:\n",
        "                    feedback = st.radio(\"How would you rate this content?\",\n",
        "                                       [\"Select Rating\", \"Excellent\", \"Good\", \"Needs Improvement\"])\n",
        "                with feedback_col2:\n",
        "                    if feedback != \"Select Rating\":\n",
        "                        improvement = st.text_area(\"What could be improved?\",\n",
        "                                                placeholder=\"Optional: Share specific feedback...\")\n",
        "                        if st.button(\"Submit Feedback\"):\n",
        "                            st.success(f\"Thank you for your '{feedback}' feedback!\")\n",
        "            else:\n",
        "                st.error(\"Failed to generate content. Please adjust your parameters and try again.\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"An unexpected error occurred: {str(e)}\")\n",
        "    elif generate_button and not topic:\n",
        "        st.warning(\"Please enter a blog topic before generating content.\")\n",
        "    if not generate_button:\n",
        "        with st.expander(\"Tips for Better Results\", expanded=True):\n",
        "            st.markdown(\"\"\"\n",
        "            - **Be specific** with your topic (e.g., \"Impact of AI on Healthcare in 2025\" instead of just \"AI\")\n",
        "            - Use **web search** for topics requiring current information\n",
        "            - Adjust **word count** based on your needs (longer posts may take more time)\n",
        "            - Choose the right **audience** to tailor the content appropriately\n",
        "            - Experiment with different **tones** to match your brand voice\n",
        "            \"\"\"\n",
        "            )\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sKkH9K7Ewi6Y",
        "outputId": "8b62e26d-e518-4138-c2b8-afb08e0551ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ask3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2eHdZgIMHJGOYt0rxlDCHqeo7vU_44HkyqKxYioU21WPu6pRh\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfLorS3zxE1s",
        "outputId": "e7bab8cf-0714-40ce-b297-dc5d059188d1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://7085-34-106-29-63.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run ask3.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "IjS4Axlpxcxr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now click the generated https link from Ngrok Tunnel after running above cell."
      ],
      "metadata": {
        "id": "M8ouWoBPQPgf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tRgVQI1P1q-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}